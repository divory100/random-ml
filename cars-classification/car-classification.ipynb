{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cda06a83",
   "metadata": {},
   "source": [
    "# Car Classification using Stanford Cars Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1578dd-cad3-447a-bb32-97635a6567c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Car image and metadata manipulation\n",
    "from cv2 import imread, imwrite, waitKey\n",
    "from scipy import io as spio\n",
    "\n",
    "#File management\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch import nn #neural network framework\n",
    "from torch import optim\n",
    "\n",
    "#hyperparameter tuning\n",
    "from ray import tune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba5409ee",
   "metadata": {},
   "source": [
    "##### 1. Load and match car metadata with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8f7ff4-2300-483c-9d00-07e89fd5a65a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "car_metadata = spio.loadmat(\"cardata/cars_meta.mat\")[\"class_names\"]\n",
    "car_train_raw = spio.loadmat(\"cardata/cars_train.mat\")[\"annotations\"]\n",
    "car_test_raw = spio.loadmat(\"cardata/cars_test.mat\")[\"annotations\"]\n",
    "\n",
    "#train/test metadata: [box x1, box y1, box x2, box y2, classnum, filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995fafba-35e8-4c3e-bb27-37980e29321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minimal prep work required for the data as just need to load the metadata and match it up with the images\n",
    "car_classes = [x[0] for x in car_metadata[0]]\n",
    "\n",
    "car_train = {\n",
    "    car[5][0]: car_classes[car[4][0][0]-1] for car in car_train_raw[0]\n",
    "} #class gives num not index therefore -1\n",
    "\n",
    "car_test = {\n",
    "    car[5][0]: car_classes[car[4][0][0]-1] for car in car_test_raw[0]\n",
    "}\n",
    "\n",
    "#format: {\"xxxxx.jpg\": \"Make Model Year\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb347cd0",
   "metadata": {},
   "source": [
    "##### 2. Crop the car images to remove unnecessary background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007c4f3-9629-4976-9f51-458479957a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#crop car images to only include the relevant bit, not background stuff\n",
    "for car in car_train_raw[0]:\n",
    "    x1, y1, x2, y2 = car[0][0][0], car[1][0][0], car[2][0][0], car[3][0][0]\n",
    "    path = f\"cardata/cars_train/{car[5][0]}\"\n",
    "    \n",
    "    image = imread(path)\n",
    "    crop = image[y1:y2, x1:x2]\n",
    "    \n",
    "    imwrite(path, crop)\n",
    "    waitKey(0)\n",
    "    \n",
    "for car in car_test_raw[0]:\n",
    "    x1, y1, x2, y2 = car[0][0][0], car[1][0][0], car[2][0][0], car[3][0][0]\n",
    "    path = f\"cardata/cars_test/{car[5][0]}\"\n",
    "    \n",
    "    image = imread(path)\n",
    "    crop = image[y1:y2, x1:x2]\n",
    "    \n",
    "    imwrite(path, crop)\n",
    "    waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81611d3",
   "metadata": {},
   "source": [
    "##### 3. Move images into class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f44edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_class in car_classes:\n",
    "    os.makedirs(f\"cardata/cars_train/{img_class}/\")\n",
    "    os.makedirs(f\"cardata/cars_test/{img_class}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9389066",
   "metadata": {},
   "outputs": [],
   "source": [
    "for car in car_train:\n",
    "    shutil.move(f\"cardata/cars_train/{car}\", f\"cardata/cars_train/{car_train[car]}/{car}\")\n",
    "\n",
    "for car in car_test:\n",
    "    shutil.move(f\"cardata/cars_test/{car}\", f\"cardata/cars_test/{car_test[car]}/{car}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de8a061a",
   "metadata": {},
   "source": [
    "##### 4. Convert, resize and normalize the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba3d75c-2c8e-4746-a552-701e2ddbf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5,0.5,0.5) #rgb; (x - mean)/std will give -1 to 1 with these values of mean and std\n",
    "std = (0.5,0.5,0.5)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 5 #n images per iteration of training\n",
    "workers = 2 #utilise multiple cores\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    \"cardata/cars_train/\", transform=transform\n",
    ")\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    \"cardata/cars_test/\", transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, #no shuffle for test set\n",
    "    num_workers=workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761a70d",
   "metadata": {},
   "source": [
    "##### 5. Defining convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f73c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        #CONVOLUTIONAL LAYERS\n",
    "        #input channels (3 as RGB), output channels, n by n square kernel\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=3, padding=1\n",
    "        )\n",
    "        #in channels of conv2 = out channels of conv1\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "\n",
    "        #POOl\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        #FULLY CONNECTED LAYERS\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 128) #output from conv2 * length * breadth of images\n",
    "        self.fc2 = nn.Linear(128, 196) #196 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        #reLU allows for non-linearity\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1, 32 * 32 * 32) #to manipulate tensors\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472b403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=32768, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=196, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25da887",
   "metadata": {},
   "source": [
    "##### 6. Optimising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "855f5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = nn.CrossEntropyLoss()\n",
    "\n",
    "#Stochastic Gradient Descent: softmax + negative log-likelihood\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4633f0",
   "metadata": {},
   "source": [
    "##### 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf9b6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1000]: Loss is 0.001\n",
      "2 [1000]: Loss is 0.001\n",
      "3 [1000]: Loss is 0.001\n",
      "4 [1000]: Loss is 0.0\n",
      "5 [1000]: Loss is 0.001\n",
      "6 [1000]: Loss is 0.0\n",
      "7 [1000]: Loss is 0.001\n",
      "8 [1000]: Loss is 1.057\n",
      "9 [1000]: Loss is 0.0\n",
      "10 [1000]: Loss is 0.0\n",
      "11 [1000]: Loss is 0.001\n",
      "12 [1000]: Loss is 0.0\n",
      "13 [1000]: Loss is 0.0\n",
      "14 [1000]: Loss is 1.056\n",
      "15 [1000]: Loss is 0.0\n",
      "16 [1000]: Loss is 0.0\n",
      "17 [1000]: Loss is 0.0\n",
      "18 [1000]: Loss is 0.0\n",
      "19 [1000]: Loss is 1.056\n",
      "20 [1000]: Loss is 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for batch_id, (input, target) in enumerate(train_loader):\n",
    "        optimiser.zero_grad() #reset\n",
    "        output = model(input) #forward pass\n",
    "\n",
    "        #calculate loss\n",
    "        ce_loss = cel(output, target)\n",
    "        ce_loss.backward() #backward pass\n",
    "\n",
    "        #optimisation\n",
    "        optimiser.step()\n",
    "\n",
    "        #metrics\n",
    "        if batch_id % 1000 == 999: #print at intervals\n",
    "            print(f\"{epoch + 1} [{batch_id+1}]: Loss is {round(ce_loss.item(), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d0102",
   "metadata": {},
   "source": [
    "##### 8. Saving the NN for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0925b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"CNN-40.pth\"\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d77aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reloading trained model if needed\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c969ae4",
   "metadata": {},
   "source": [
    "##### 9. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf7e5c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.603034448451686% accuracy\n"
     ]
    }
   ],
   "source": [
    "t = 0 #total\n",
    "c = 0 #total correct\n",
    "\n",
    "with torch.no_grad():\n",
    "    for car in test_loader:\n",
    "        input, target = car\n",
    "        output = model(input)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "\n",
    "        t += target.size(0)\n",
    "        c += (pred == target).sum().item()\n",
    "\n",
    "accuracy = 100*(c/t)\n",
    "print(f\"{accuracy}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf510d9",
   "metadata": {},
   "source": [
    "##### 5. Tuning\n",
    "WIP: using ray tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5fe11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
